{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from osgeo import gdal, ogr\n",
    "import torch\n",
    "import geopandas as gpd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from geonet import tiler, mask, raster, dataset\n",
    "from geonet.visualizations import plotImagePair\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_image = \"../../data/_mvp/liski_jj_20-3857.tif\"\n",
    "src_vector = \"../../data/_mvp/belgorod_train.shp\"\n",
    "tiles_dir = \"../../data/_mvp/agro20jj_train_tiles\"\n",
    "labels_dir = \"../../data/_mvp/agro_train_labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Tiler...\n",
      "Tiler initialized.\n",
      "dest_dir: ../../data/_mvp/agro20jj_train_tiles\n",
      "dest_crs will be inferred from source data.\n",
      "src_tile_size: (512, 512)\n",
      "tile size units metric: False\n",
      "Resampling is set to None\n"
     ]
    }
   ],
   "source": [
    "raster_tiler = tiler.RasterTiler(dest_dir=tiles_dir, src_tile_size=(512, 512), tile_overlay=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tiling...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb32562ee75446dae6d2c5d7e6b44ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input data...\n",
      "[1, 2, 3, 4]\n",
      "Source CRS: EPSG:3857\n",
      "Destination CRS: EPSG:3857\n",
      "Inputs OK.\n",
      "count of tile bounds 576\n",
      "\n",
      "Tiling complete. Cleaning up...\n",
      "Done. CRS returned for vector tiling.\n"
     ]
    }
   ],
   "source": [
    "raster_bounds_crs = raster_tiler.tile(src_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the tiler...\n",
      "Initialization done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fbab37bc1446519dfa6b4c2ac29d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tiles: 304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_tiler = tiler.VectorTiler(dest_dir=labels_dir, verbose=True)\n",
    "vector_tiler.tile(src_vector,\n",
    "                  tile_bounds=raster_tiler.tile_bounds,\n",
    "                  tile_bounds_crs=raster_bounds_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(path, prefix):\n",
    "    files = os.listdir(path)\n",
    "    for index, file in enumerate(files):\n",
    "        os.rename(os.path.join(path, file), os.path.join(path, prefix+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_prefix(\"../../data/_mvp/agro_train_labels/bel_v/\", \"bel_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1826\n",
      "1826\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"../../data/_mvp/agro20jj_train_tiles/\")\n",
    "#labels = os.listdir(\"../../data/_mvp/agro19_train_labels/\")\n",
    "masks = os.listdir(\"../../data/_mvp/agro20jj_train_masks/\")\n",
    "images.sort()\n",
    "#labels.sort()\n",
    "masks.sort()\n",
    "print(len(images))\n",
    "#print(len(labels))\n",
    "print(len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['borisoglebsk_jj_20-3857_4660971_6679049.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6686803.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6694556.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6702310.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6710064.tif']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bel_trgeoms_4020878_6524396.geojson',\n",
       " 'bel_trgeoms_4020878_6531968.geojson',\n",
       " 'bel_trgeoms_4020878_6539541.geojson',\n",
       " 'bel_trgeoms_4020878_6547113.geojson',\n",
       " 'bel_trgeoms_4020878_6554686.geojson']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6679049.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6686803.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6694556.tif',\n",
       " 'borisoglebsk_jj_20-3857_4660971_6702310.tif']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"../../data/_mvp/agro20jj_test_tiles/.ipynb_checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(images)):\n",
    "    gdf = gpd.read_file(labels_dir + '/' + labels[i])\n",
    "    ref_im = tiles_dir + '/' + images[i]\n",
    "    fp_mask = mask.footprint_mask(gdf, reference_im=ref_im, do_transform=\"reference_im\")\n",
    "    #b_mask = mask.boundary_mask(fp_mask, boundary_width=5)\n",
    "    try:\n",
    "        #c_mask = mask.contact_mask(gdf, reference_im=ref_im, contact_spacing=5)\n",
    "        #mask_full = np.dstack((fp_mask, b_mask, c_mask))\n",
    "        mask_im = \"../../data/_mvp/agro_train_masks/\" + images[i]\n",
    "        Image.fromarray(fp_mask).save(mask_im)\n",
    "    except:\n",
    "        os.remove(\"../../data/_mvp/agro_train_labels/\" + labels[i])\n",
    "        os.remove(\"../../data/_mvp/agro_train_tiles/\" + images[i])\n",
    "        print(labels[i] + \" processing failed. Files removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split files on train and test\n",
    "def test_split(train_dir, train_masks_dir, test_dir, test_masks_dir, shape, per=0.3):\n",
    "    k = np.int(np.round(shape * per))\n",
    "    test_idx = random.sample(range(0, shape), k)\n",
    "    file_names = os.listdir(train_dir)\n",
    "    i = 0\n",
    "    for file_name in file_names:\n",
    "        if i in test_idx:\n",
    "            shutil.move(os.path.join(train_dir, file_name), test_dir)\n",
    "            shutil.move(os.path.join(train_masks_dir, file_name), test_masks_dir)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(\"../../data/_mvp/agro20jj_train_masks/v/\")): \n",
    "    dst = filename.split(\"_\")\n",
    "    del dst[0:2]\n",
    "    dst = '_'.join(dst)\n",
    "    dst = 'vrn_20-07_'+dst\n",
    "    src =\"../../data/_mvp/agro20jj_train_masks/v/\" + filename \n",
    "    dst =\"../../data/_mvp/agro20jj_train_masks/v/\" + dst \n",
    "          \n",
    "    # rename() function will \n",
    "    # rename all the files \n",
    "    os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split(\"../../data/_mvp/agro20jj_train_tiles/\", \"../../data/_mvp/agro20jj_train_masks/\",\n",
    "          \"../../data/_mvp/agro20jj_test_tiles/\", \"../../data/_mvp/agro20jj_test_masks/\", shape=1826, per=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add augmentations\n",
    "aug = A.Compose([\n",
    "    #A.Normalize(mean=(0.0095, 0.0087, 0.0078), std=(0.0075, 0.0070, 0.0060)),\n",
    "    A.RandomRotate90(p=0.4),\n",
    "    A.Flip(p=0.4),\n",
    "    A.GridDistortion(p=0.4),\n",
    "    #A.Downscale(scale_min=0.2, scale_max=0.3, p=0.3),\n",
    "    A.Transpose(p=0.4),\n",
    "    #A.Lambda(image=preprocess_input),\n",
    "    A.Lambda(image=to_tensor),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def preprocess_input(x, mean=[0.485, 0.456, 0.406, 0.405], std=[0.229, 0.224, 0.225, 0.225], input_space=\"RGB\", input_range=[0,1], **kwargs):\n",
    "\n",
    "    if input_space == \"BGR\":\n",
    "        x = x[..., ::-1].copy()\n",
    "\n",
    "    if input_range is not None:\n",
    "        if x.max() > 1 and input_range[1] == 1:\n",
    "            x = x / 255.0\n",
    "\n",
    "    if mean is not None:\n",
    "        mean = np.array(mean)\n",
    "        x = x - mean\n",
    "\n",
    "    if std is not None:\n",
    "        std = np.array(std)\n",
    "        x = x / std\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.RandomRotate90(p=0.4),\n",
    "        A.Flip(p=0.4),\n",
    "        A.GridDistortion(p=0.4),\n",
    "        #A.Downscale(scale_min=0.2, scale_max=0.3, p=0.3),\n",
    "        A.Transpose(p=0.4),\n",
    "        A.Lambda(image=preprocess_input),\n",
    "        A.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocess_input),\n",
    "        A.Lambda(image=to_tensor)\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['agro']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.FPN(\n",
    "    encoder_name=ENCODER, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    "    in_channels=4,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DVL/glotovaa/projects/data_science/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "trainData = dataset.TiledRasterDataset(\"../../data/_mvp/agro20jj_train_tiles/\", \"../../data/_mvp/agro20jj_train_masks/\", classes=[\"agro\"], preprocessing=get_preprocessing(preprocessing_fn))\n",
    "validData = dataset.TiledRasterDataset(\"../../data/_mvp/agro20jj_test_tiles/\", \"../../data/_mvp/agro20jj_test_masks/\", classes=[\"agro\"], preprocessing=get_preprocessing(preprocessing_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train_file = raster.get_array_from_tiff(\"../../data/_mvp/liski_3857.tif\")\\nx_train_file = np.dstack(x_train_file)\\ny_train_file = raster.get_array_from_tiff(\"../../data/_mvp/liski_agro_mask.tif\")[0]\\n#x_valid_file = raster.get_array_from_tiff(\"../../data/_mvp/vrn_train_3857.tif\")\\n#x_valid_file = np.dstack(x_valid_file)\\n#y_valid_file = raster.get_array_from_tiff(\"../../data/_mvp/vrn_3857_mask.tif\")[0]\\ntrainData2 = dataset.RasterDataset(x_train_file.astype(float), y_train_file.astype(float), classes=[\"agro\"], preprocessing=get_preprocessing(preprocessing_fn))\\nvalidData2 = dataset.RasterDataset(x_train_file.astype(float), y_train_file.astype(float), classes=[\"agro\"], preprocessing=get_preprocessing(preprocessing_fn))\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_train_file = raster.get_array_from_tiff(\"../../data/_mvp/liski_3857.tif\")\n",
    "x_train_file = np.dstack(x_train_file)\n",
    "y_train_file = raster.get_array_from_tiff(\"../../data/_mvp/liski_agro_mask.tif\")[0]\n",
    "#x_valid_file = raster.get_array_from_tiff(\"../../data/_mvp/vrn_train_3857.tif\")\n",
    "#x_valid_file = np.dstack(x_valid_file)\n",
    "#y_valid_file = raster.get_array_from_tiff(\"../../data/_mvp/vrn_3857_mask.tif\")[0]\n",
    "trainData2 = dataset.RasterDataset(x_train_file.astype(float), y_train_file.astype(float), classes=[\"agro\"], preprocessing=get_preprocessing(preprocessing_fn))\n",
    "validData2 = dataset.RasterDataset(x_train_file.astype(float), y_train_file.astype(float), classes=[\"agro\"], preprocessing=get_preprocessing(preprocessing_fn))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data loaders\n",
    "train_loader = DataLoader(trainData, batch_size=1, shuffle=True, num_workers=3)\n",
    "valid_loader = DataLoader(validData, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW([ \n",
    "    dict(params=model.parameters(), lr=0.00015),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device = DEVICE,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): SENetEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (4): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (p5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (seg_blocks): ModuleList(\n",
       "      (0): SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SegmentationBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv3x3GNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (merge): MergeBlock()\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n",
       "    (2): Activation(\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 1278/1278 [02:00<00:00, 10.65it/s, dice_loss - 0.3058, iou_score - 0.6088]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.75it/s, dice_loss - 0.1785, iou_score - 0.7456]\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.2681, iou_score - 0.6562]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.28it/s, dice_loss - 0.2093, iou_score - 0.7667]\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 1278/1278 [02:03<00:00, 10.32it/s, dice_loss - 0.2546, iou_score - 0.6735]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.25it/s, dice_loss - 0.2375, iou_score - 0.7452]\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|██████████| 1278/1278 [02:03<00:00, 10.33it/s, dice_loss - 0.2493, iou_score - 0.6797]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.29it/s, dice_loss - 0.1611, iou_score - 0.7769]\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|██████████| 1278/1278 [02:03<00:00, 10.31it/s, dice_loss - 0.2224, iou_score - 0.7085]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.28it/s, dice_loss - 0.1575, iou_score - 0.7786]\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|██████████| 1278/1278 [02:03<00:00, 10.31it/s, dice_loss - 0.2038, iou_score - 0.7285]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.22it/s, dice_loss - 0.6832, iou_score - 0.247] \n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.30it/s, dice_loss - 0.1558, iou_score - 0.7777]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.23it/s, dice_loss - 0.1657, iou_score - 0.7641]\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.1481, iou_score - 0.7854]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.19it/s, dice_loss - 0.2365, iou_score - 0.706] \n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.145, iou_score - 0.7883] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.1655, iou_score - 0.7784]\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1474, iou_score - 0.786] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.2419, iou_score - 0.7577]\n",
      "\n",
      "Epoch: 10\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1617, iou_score - 0.7728]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.24it/s, dice_loss - 0.1996, iou_score - 0.7166]\n",
      "\n",
      "Epoch: 11\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1474, iou_score - 0.7867]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.17it/s, dice_loss - 0.2215, iou_score - 0.7089]\n",
      "\n",
      "Epoch: 12\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1419, iou_score - 0.7937]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.14it/s, dice_loss - 0.1512, iou_score - 0.7797]\n",
      "\n",
      "Epoch: 13\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1417, iou_score - 0.7945]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.11it/s, dice_loss - 0.1722, iou_score - 0.7502]\n",
      "\n",
      "Epoch: 14\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1404, iou_score - 0.7959]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.23it/s, dice_loss - 0.1836, iou_score - 0.7294]\n",
      "\n",
      "Epoch: 15\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1414, iou_score - 0.7955]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.20it/s, dice_loss - 0.1737, iou_score - 0.7483]\n",
      "Decrease decoder learning rate to 7e-5!\n",
      "\n",
      "Epoch: 16\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.2101, iou_score - 0.7274]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.16it/s, dice_loss - 0.1363, iou_score - 0.7962]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 17\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1302, iou_score - 0.8093]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.24it/s, dice_loss - 0.1738, iou_score - 0.7451]\n",
      "\n",
      "Epoch: 18\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1288, iou_score - 0.8108]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.15it/s, dice_loss - 0.1636, iou_score - 0.7511]\n",
      "\n",
      "Epoch: 19\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1268, iou_score - 0.8134]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.06it/s, dice_loss - 0.1648, iou_score - 0.7584]\n",
      "\n",
      "Epoch: 20\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1254, iou_score - 0.8155]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.11it/s, dice_loss - 0.1712, iou_score - 0.7971]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 21\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1224, iou_score - 0.819] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.2136, iou_score - 0.7996]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 22\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.1254, iou_score - 0.8156]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.15it/s, dice_loss - 0.1435, iou_score - 0.8182]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 23\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1267, iou_score - 0.8142]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.21it/s, dice_loss - 0.1711, iou_score - 0.7415]\n",
      "\n",
      "Epoch: 24\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1229, iou_score - 0.8185]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.16it/s, dice_loss - 0.219, iou_score - 0.6812] \n",
      "\n",
      "Epoch: 25\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1217, iou_score - 0.8207]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.21it/s, dice_loss - 0.2194, iou_score - 0.7161]\n",
      "\n",
      "Epoch: 26\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1251, iou_score - 0.8165]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.13it/s, dice_loss - 0.1803, iou_score - 0.7734]\n",
      "\n",
      "Epoch: 27\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1283, iou_score - 0.8123]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.02it/s, dice_loss - 0.1274, iou_score - 0.807] \n",
      "\n",
      "Epoch: 28\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1102, iou_score - 0.8325]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.23it/s, dice_loss - 0.1397, iou_score - 0.785] \n",
      "\n",
      "Epoch: 29\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.122, iou_score - 0.821]  \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.25it/s, dice_loss - 0.1278, iou_score - 0.8068]\n",
      "\n",
      "Epoch: 30\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1044, iou_score - 0.8372]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.1217, iou_score - 0.81]  \n",
      "\n",
      "Epoch: 31\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1099, iou_score - 0.8325]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.08it/s, dice_loss - 0.2171, iou_score - 0.7195]\n",
      "\n",
      "Epoch: 32\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.1053, iou_score - 0.8361]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.24it/s, dice_loss - 0.2276, iou_score - 0.7041]\n",
      "\n",
      "Epoch: 33\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1034, iou_score - 0.8393]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.17it/s, dice_loss - 0.1878, iou_score - 0.7272]\n",
      "\n",
      "Epoch: 34\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.1079, iou_score - 0.8343]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.33it/s, dice_loss - 0.2055, iou_score - 0.7007]\n",
      "\n",
      "Epoch: 35\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1043, iou_score - 0.8386]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.15it/s, dice_loss - 0.2296, iou_score - 0.7038]\n",
      "\n",
      "Epoch: 36\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1206, iou_score - 0.8201]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.19it/s, dice_loss - 0.1246, iou_score - 0.8085]\n",
      "\n",
      "Epoch: 37\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1073, iou_score - 0.8343]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.21it/s, dice_loss - 0.1418, iou_score - 0.7821]\n",
      "\n",
      "Epoch: 38\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09746, iou_score - 0.845] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.22it/s, dice_loss - 0.1246, iou_score - 0.8089]\n",
      "\n",
      "Epoch: 39\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09925, iou_score - 0.8433]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.25it/s, dice_loss - 0.1186, iou_score - 0.814] \n",
      "\n",
      "Epoch: 40\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1018, iou_score - 0.8419] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.22it/s, dice_loss - 0.1269, iou_score - 0.8099]\n",
      "\n",
      "Epoch: 41\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1028, iou_score - 0.8398] \n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.12it/s, dice_loss - 0.136, iou_score - 0.7927] \n",
      "\n",
      "Epoch: 42\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.1044, iou_score - 0.8386]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.17it/s, dice_loss - 0.2466, iou_score - 0.6836]\n",
      "\n",
      "Epoch: 43\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09375, iou_score - 0.8485]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.21it/s, dice_loss - 0.1527, iou_score - 0.7706]\n",
      "\n",
      "Epoch: 44\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1153, iou_score - 0.827] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.19it/s, dice_loss - 0.1274, iou_score - 0.7998]\n",
      "\n",
      "Epoch: 45\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1425, iou_score - 0.8]   \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.2116, iou_score - 0.697] \n",
      "\n",
      "Epoch: 46\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1201, iou_score - 0.8227]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.29it/s, dice_loss - 0.1449, iou_score - 0.7862]\n",
      "\n",
      "Epoch: 47\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1285, iou_score - 0.8145]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.22it/s, dice_loss - 0.1691, iou_score - 0.7492]\n",
      "\n",
      "Epoch: 48\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1172, iou_score - 0.8241]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.23it/s, dice_loss - 0.13, iou_score - 0.8005]  \n",
      "\n",
      "Epoch: 49\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1118, iou_score - 0.8295]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.14it/s, dice_loss - 0.1793, iou_score - 0.7306]\n",
      "\n",
      "Epoch: 50\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1042, iou_score - 0.839] \n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.29it/s, dice_loss - 0.1928, iou_score - 0.7145]\n",
      "\n",
      "Epoch: 51\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09345, iou_score - 0.8497]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.228, iou_score - 0.6957] \n",
      "\n",
      "Epoch: 52\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1006, iou_score - 0.8428] \n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.10it/s, dice_loss - 0.2701, iou_score - 0.6202]\n",
      "\n",
      "Epoch: 53\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09316, iou_score - 0.8506]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.19it/s, dice_loss - 0.1515, iou_score - 0.7682]\n",
      "\n",
      "Epoch: 54\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09622, iou_score - 0.8477]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.13it/s, dice_loss - 0.1695, iou_score - 0.7413]\n",
      "\n",
      "Epoch: 55\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09036, iou_score - 0.8532]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.12it/s, dice_loss - 0.22, iou_score - 0.714]   \n",
      "\n",
      "Epoch: 56\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.08804, iou_score - 0.8568]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.20it/s, dice_loss - 0.1231, iou_score - 0.8088]\n",
      "\n",
      "Epoch: 57\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09752, iou_score - 0.8458]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.17it/s, dice_loss - 0.2445, iou_score - 0.6878]\n",
      "\n",
      "Epoch: 58\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.1052, iou_score - 0.8377]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.14it/s, dice_loss - 0.2481, iou_score - 0.683] \n",
      "\n",
      "Epoch: 59\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1056, iou_score - 0.8376]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.27it/s, dice_loss - 0.1525, iou_score - 0.7768]\n",
      "\n",
      "Epoch: 60\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1156, iou_score - 0.8268]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.14it/s, dice_loss - 0.2651, iou_score - 0.6533]\n",
      "\n",
      "Epoch: 61\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.27it/s, dice_loss - 0.1056, iou_score - 0.8381]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.07it/s, dice_loss - 0.1915, iou_score - 0.7233]\n",
      "\n",
      "Epoch: 62\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09281, iou_score - 0.8511]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.15it/s, dice_loss - 0.1175, iou_score - 0.8182]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 63\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.29it/s, dice_loss - 0.1183, iou_score - 0.8256]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.18it/s, dice_loss - 0.2336, iou_score - 0.6987]\n",
      "\n",
      "Epoch: 64\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09667, iou_score - 0.8467]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.23it/s, dice_loss - 0.2257, iou_score - 0.7062]\n",
      "\n",
      "Epoch: 65\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09151, iou_score - 0.8528]\n",
      "valid: 100%|██████████| 548/548 [00:13<00:00, 39.19it/s, dice_loss - 0.2216, iou_score - 0.7105]\n",
      "\n",
      "Epoch: 66\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.28it/s, dice_loss - 0.09144, iou_score - 0.8524]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.12it/s, dice_loss - 0.2347, iou_score - 0.697] \n",
      "\n",
      "Epoch: 67\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.25it/s, dice_loss - 0.104, iou_score - 0.8393]  \n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.07it/s, dice_loss - 0.1452, iou_score - 0.7841]\n",
      "\n",
      "Epoch: 68\n",
      "train: 100%|██████████| 1278/1278 [02:04<00:00, 10.23it/s, dice_loss - 0.1107, iou_score - 0.8327]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 39.07it/s, dice_loss - 0.229, iou_score - 0.6982] \n",
      "\n",
      "Epoch: 69\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.22it/s, dice_loss - 0.09145, iou_score - 0.8539]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.86it/s, dice_loss - 0.2348, iou_score - 0.6964]\n",
      "\n",
      "Epoch: 70\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.21it/s, dice_loss - 0.09244, iou_score - 0.8519]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.93it/s, dice_loss - 0.2216, iou_score - 0.7163]\n",
      "\n",
      "Epoch: 71\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.21it/s, dice_loss - 0.09464, iou_score - 0.8504]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.80it/s, dice_loss - 0.1515, iou_score - 0.7795]\n",
      "\n",
      "Epoch: 72\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.20it/s, dice_loss - 0.1067, iou_score - 0.8367]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.86it/s, dice_loss - 0.2344, iou_score - 0.6978]\n",
      "\n",
      "Epoch: 73\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.20it/s, dice_loss - 0.08886, iou_score - 0.8556]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.82it/s, dice_loss - 0.2402, iou_score - 0.6831]\n",
      "\n",
      "Epoch: 74\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.21it/s, dice_loss - 0.08626, iou_score - 0.8588]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.86it/s, dice_loss - 0.2309, iou_score - 0.6999]\n",
      "\n",
      "Epoch: 75\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.19it/s, dice_loss - 0.08634, iou_score - 0.8593]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.88it/s, dice_loss - 0.2372, iou_score - 0.6947]\n",
      "\n",
      "Epoch: 76\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.20it/s, dice_loss - 0.09447, iou_score - 0.8499]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.83it/s, dice_loss - 0.225, iou_score - 0.6997] \n",
      "\n",
      "Epoch: 77\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.20it/s, dice_loss - 0.1042, iou_score - 0.8416]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.91it/s, dice_loss - 0.2544, iou_score - 0.638] \n",
      "\n",
      "Epoch: 78\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.19it/s, dice_loss - 0.09491, iou_score - 0.8499]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.91it/s, dice_loss - 0.1955, iou_score - 0.7099]\n",
      "\n",
      "Epoch: 79\n",
      "train: 100%|██████████| 1278/1278 [02:05<00:00, 10.21it/s, dice_loss - 0.1021, iou_score - 0.8439]\n",
      "valid: 100%|██████████| 548/548 [00:14<00:00, 38.82it/s, dice_loss - 0.2382, iou_score - 0.6917]\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "max_score = 0.78\n",
    "'''checkpoint = torch.load(\"./weights/best/agronet_chekpoint_v1.3 - 0.7770444019770664.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']'''\n",
    "\n",
    "for i in range(0, 80):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, './weights/agronet-20_07_v1.3 - {}.pth'.format(max_score))\n",
    "        torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, './weights/agronet-20_07_v1.3-chekpoint - {}.pth'.format(max_score))\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 15:\n",
    "        optimizer.param_groups[0]['lr'] = 7e-5\n",
    "        print('Decrease decoder learning rate to 7e-5!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's inference\n",
    "    best_model = torch.load('../geonet/weights/agronet-20_07_v1.3 - 0.8182464988102082.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(img, mas, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = raster.get_array_from_tiff(\"../../data/_mvp/vrn_19_3857.tif\")\n",
    "img = np.dstack(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = raster.get_array_from_tiff(\"../../data/_mvp/vrn_3857_mask.tif\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DVL/glotovaa/projects/data_science/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "testData = dataset.RasterDataset(img, mas, classes=['agro'], step=384, preprocessing=get_inference_preprocessing(preprocessing_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testData, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_x = np.zeros(shape=(img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "step = 384\n",
    "tile_size = 512\n",
    "xc = round(img.shape[0] / step) + 1\n",
    "yc = round(img.shape[1] / step) + 1\n",
    "\n",
    "i = 0\n",
    "for batch in test_loader:\n",
    "    m = i % xc\n",
    "    j = i // xc\n",
    "    #x_tensor = torch.from_numpy(batch[0]).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(batch[0].cuda())\n",
    "    pr_mask = (pr_mask.cpu().numpy().round(3))\n",
    "    '''if i < 5:\n",
    "        plotImagePair(\n",
    "        image=batch[0][0].reshape(512, 512, 4), \n",
    "        #ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask\n",
    "    )'''\n",
    "            \n",
    "    if (step*m+tile_size) > img.shape[0]:\n",
    "        if (step*j+tile_size) > img.shape[1]:\n",
    "            ext_x[(img.shape[0]-tile_size):img.shape[0], (img.shape[1]-tile_size):img.shape[1]] = np.maximum(ext_x[(img.shape[0]-tile_size):img.shape[0], (img.shape[1]-tile_size):img.shape[1]], pr_mask)\n",
    "        else:\n",
    "            ext_x[(img.shape[0]-tile_size):img.shape[0], step*j:(step*j+tile_size)] = np.maximum(ext_x[(img.shape[0]-tile_size):img.shape[0], step*j:(step*j+tile_size)], pr_mask)\n",
    "    elif (step*j+tile_size) > img.shape[1]:\n",
    "        ext_x[step*m:(step*m+tile_size), (img.shape[1]-tile_size):img.shape[1]] = np.maximum(ext_x[step*m:(step*m+tile_size), (img.shape[1]-tile_size):img.shape[1]], pr_mask)\n",
    "    else:\n",
    "        ext_x[step*m:(step*m+tile_size), step*j:(step*j+tile_size)] = np.maximum(ext_x[step*m:(step*m+tile_size), step*j:(step*j+tile_size)], pr_mask)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "raster.get_raster_from_array(ext_x, \"../../data_science/mvp/vrn_20-07_agro_predicted_v.1.3.tif\", \"../../data/_mvp/vrn_train_3857.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceRaster = gdal.Open(\"../agronet/data/kursk_predicted.tif\")\n",
    "band = sourceRaster.GetRasterBand(1)\n",
    "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "outDatasource = driver.CreateDataSource(\"../agronet/data/kursk_vector.shp\")\n",
    "outLayer = outDatasource.CreateLayer(\"polygonized\", srs=None, OGRwkbGeometryType)\n",
    "newField = ogr.FieldDefn('MYFLD', ogr.OFTInteger)\n",
    "outLayer.CreateField(newField)\n",
    "gdal.Polygonize(band, None, outLayer, 1, [], callback=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
